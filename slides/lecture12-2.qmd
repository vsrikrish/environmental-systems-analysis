---
title: "Simulation-Optimization"
subtitle: "Lecture 23"
author: "Vivek Srikrishnan"
course: "BEE 4750"
institution: "Cornell University"
date: "November 8, 2023"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        footer: "[BEE 4750, Environmental Systems Analysis](https://viveks.me/environmental-systems-analysis)"
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long

execute:
    freeze: auto
---

```{julia}
import Pkg
Pkg.activate(".")
Pkg.instantiate()
```

```{julia}
using Random
using Optim
using Roots
using Distributions
using Plots
using LaTeXStrings
using Measures
using Metaheuristics
```

# Review and Questions

## Mathematical Programming and Systems Analysis

:::: {.columns}
::: {.column width=50%}
**Pros**:

- Can guarantee analytic solutions (or close)
- Often computationally scalable (especially for LPs)
- Transparent

:::

::: {.column width=50%}
**Cons**:

- Often quite stylized
- Limited ability to treat uncertainty

:::
::::

## Mathematical Programming and Systems Analysis

Challenges include:

- Complex and non-linear systems dynamics;
- Uncertainties;
- Multiple objectives.



# Simulation-Optimization

## Simulation-Optimization

:::: {.columns}
::: {.column width=45%}
**Simulation-Optimization** involves the use of a simulation model to map decision variables and other inputs to system outputs.

:::
::: {.column width=55%}
![Mathematical Model](images/math-model.png)
:::
::::

## Simulation-Optimization

:::: {.columns}
::: {.column width=50%}
What kinds of methods can use for simulation-optimization?

:::
::: {.column width=50%}
![Mathematical Model](images/math-model.png)
:::
::::

## Simulation-Optimization: Methods

:::: {.columns}
::: {.column width=50%}
**Challenge**: Underlying structure of the simulation model $f(x)$ is unknown and can be complex.

We can use a search algorithm to navigate the **response surface** of the model and find an "optimum".
:::

::: {.column width=50%}
![Mathematical Model](images/math-model.png)
:::
::::

## Why "Optimum" in Quotes?

We usually can't guarantee that we can find an optimum (or even quantify an *optimality gap*) because:

- Simulation-optimization is applied in very general settings;
- May not have much *a priori* information about the response surface;
- The response surface can be highly nonlinear.

## Why "Optimum" in Quotes?

But:

::: {.quote}
The  **optimal  solution  of  a  model  is  not  an  optimal  solution  of  a  problem  unless  the  model  is a  perfect  representation  of the  problem**,  which  it  never  is.

::: {.cite}
--- Ackoff, R. L. (1979). "The Future of Operational Research is Past." *The Journal of the Operational Research Society*, 30(2), 93â€“104. <https://doi.org/10.1057/jors.1979.22>
:::
:::

## Simulation-Optimization and Heuristics

Simulation-optimization methods typically rely on **heuristics** to decide that a solution is good enough. These can include

- number of evaluations/iterations; or
- lack of improvement of solution with increased evaluations.



## Gradient Descent

:::: {.columns}
::: {.column width=50%}
Find estimate of gradient near current point and step in positive/negative direction (depending on max/min).

$$x_{n+1} = x_n \pm \alpha_n \nabla f(x_n)$$

:::
::: {.column width=50%}
```{julia}
f(x) = 4 .* x.^4 - 10 .* (x.+2).^3 - 6 .* (x.-15).^2 + 2 .* (x.+4).^2
x = -4:0.01:5

plot(x, f(x), grid=false, linewidth=3, label=false, yticks=false, xticks=false, ylabel="Objective", xlabel="Decision Variable", left_margin=8mm, right_margin=5mm, legendfontsize=16, guidefontsize=16)
scatter!([-2.36 3.69], f.([-2.36 3.69]), color=[:blue :red], markersize=[8 12], label=["Local Optimum" "Global Optimum"])
ylims!((-1800, -1100))
xlims!((-4, 5))
scatter!([0], [f(0)], color=:black, label="Start Point", markersize=6)
plot!([0, 0], [-1800, f(0)], color=:gray, linestyle=:dot, label=:false)
plot!([-1, -1], [-1800, f(-1)], color=:gray, linestyle=:dot, label=:false)
plot!([-1.75, -1.75], [-1800, f(-1.75)], color=:gray, linestyle=:dot, label=:false)
quiver!([0], [-1775], quiver=([-1], [0]), color=:red)
quiver!([-1], [-1775], quiver=([-0.75], [0]), color=:red)
annotate!([0.25], [-1750], text(L"x_1", :red, 18))
annotate!([-0.75], [-1750], text(L"x_2", :red, 18))
annotate!([-1.5], [-1750], text(L"x_3", :red, 18))
plot!(size=(600, 500))
```
:::
::::

## Gradient Descent: Challenges

1. Need to tune stepsize for convergence; some use adaptive methods;
2. May not have information about the gradient.

::: {.fragment .fade-in}
The second is more problematic: in some cases, methods like stochastic gradient approximation or automatic differentiation can be used.
:::

## "Random" Search

:::: {.columns}
::: {.column width=50%}
Use a sampling strategy to find a new proposal, then evaluate, keep if improvement.

**Evolutionary Algorithms** fall into this category.
:::
::: {.column width=50%}
```{julia}

f(x) = 4 .* x.^4 - 10 .* (x.+2).^3 - 6 .* (x.-15).^2 + 2 .* (x.+4).^2
x = -4:0.01:5

plot(x, f(x), grid=false, linewidth=3, label=false, yticks=false, xticks=false, ylabel="Objective", xlabel="Decision Variable", left_margin=8mm, legendfontsize=16, guidefontsize=16)
scatter!([-2.36 3.69], f.([-2.36 3.69]), color=[:blue :red], markersize=[10 12], label=["Local Optimum" "Global Optimum"])
ylims!((-1800, -1100))
xlims!((-4, 5))
Random.seed!(1)
y = -4 .+ 9 .* rand(5)
scatter!([y], [f.(y)], color=:black, label=:false, markersize=8)
annotate!([y[1] + 0.5], [f.(y[1])], text(L"x_1", :black, 18))
annotate!([y[2] + 0.5], [f.(y[2])], text(L"x_2", :black, 18))
annotate!([y[3] + 0.5], [f.(y[3])], text(L"x_3", :black, 18))
annotate!([y[4] + 0.5], [f.(y[4])], text(L"x_4", :black, 18))
annotate!([y[5] + 0.5], [f.(y[5])], text(L"x_5", :black, 18))
plot!(size=(600, 500))
```
:::
::::

## Random Search with Constraints

:::: {.columns}
::: {.column width=50%}
Can also incorporate constraints into search.
:::
::: {.column width=50%}
```{julia}
f(x) = 4 .* x.^4 - 10 .* (x.+2).^3 - 6 .* (x.-15).^2 + 2 .* (x.+4).^2
x1 = -4:0.01:3.1
x2 = 3.1:0.01:5
plot(x1, f(x1), grid=false, linewidth=3, label=false, yticks=false, xticks=false, ylabel="Objective", xlabel="Decision Variable", left_margin=8mm, legendfontsize=16, guidefontsize=16)
plot!(x2, f(x2), linestyle=:dash, color=:purple, linewidth=3, label=false)
vline!([3.1], color=:orange, linewidth=5, label=false)
scatter!([-2.36 3.1], f.([-2.36 3.1]), color=[:blue :red], markersize=[10 12], label=["Local Optimum" "Constrained Optimum"])
ylims!((-1800, -1100))
xlims!((-4, 5))
Random.seed!(1)
y = -4 .+ 9 .* rand(5)
scatter!([y[1:4]], [f.(y[1:4])], color=:black, label=:false, markersize=8)
scatter!([(y[5], f(y[5]))], color=:orange, label=:false, markersize=8)
annotate!([y[1] + 0.5], [f.(y[1])], text(L"x_1", :black, 18))
annotate!([y[2] + 0.5], [f.(y[2])], text(L"x_2", :black, 18))
annotate!([y[3] + 0.5], [f.(y[3])], text(L"x_3", :black, 18))
annotate!([y[4] + 0.5], [f.(y[4])], text(L"x_4", :black, 18))
annotate!([y[5] + 0.5], [f.(y[5])], text(L"x_5", :orange, 18))
plot!(size=(600, 500))
```
:::
::::

## Random Search in Julia

Two main packages:

- [`Metaheuristics.jl`](https://docs.juliahub.com/Metaheuristics/aJ70z/3.2.12/)
- [`BlackBoxOptim.jl`](https://github.com/robertfeldt/BlackBoxOptim.jl)

## Quick Example

```{julia}
#| echo: true
Random.seed!(1)
# define function to optimize
function f(x)
    lnorm = LogNormal(0.25, 1) 
    y = rand(lnorm)
    return sum(x .- y)^2
end
fobj(x) = mean([f(x) for i in 1:1000])
bounds = [0.0 1000.0]'
# optimize
results = Metaheuristics.optimize(fobj, bounds, DE())
results.best_sol
```

## `Metaheuristics.jl` Algorithms

`Metaheuristics.jl` contains [a number of algorithms](https://docs.juliahub.com/Metaheuristics/aJ70z/3.2.12/algorithms/), covering a variety of single-objective and multi-objective algorithms.

We won't go into details here, and will just stick with `DE()` (differential evolution) in our examples.

# Lake Problem Revisited

## Lake Model

:::: {.columns}
::: {.column width=45%}
\begin{align*}
X_{t+1} &= X_t + a_t + y_t \\
&\quad + \frac{X_t^q}{1 + X_t^q} - bX_t,\\[0.5em] 
y_t &\sim \text{LogNormal}(\mu, \sigma^2)

\end{align*}
:::
::: {.column width=55%}

| Parameter | Definition |
|:-----:|:----------|
| $X_t$ | P concentration in lake | 
| $a_t$ | point source P input | 
| $y_t$ | non-point source P input | 
| $q$ | P recycling rate |
| $b$ | rate at which P is lost | 
:::
::::


## Lake Problem: Simulation-Optimization Setup

- Time period: $T=100$
- Non-point source P inflows: $y_t \sim \text{LogNormal}(0.03, 0.25).$
- $b = 2.5$ (P recycling rate), $q=0.4$ (P outflow rate)
- Constraint: $\mathbb{P}[\text{Eutrophication}] \leq 0.1$
- Objective: Maximize average point source P releases $\sum_t a_t / T$.

## Lake Problem: Exogenous P Input Distribution

```{julia}
#| echo: false

# set parameters
q = 2.5
b = 0.4
T = 100
nsamples = 1000

Random.seed!(1)
lnorm = LogNormal(log(0.03), 0.25)
y = rand(lnorm, (T, nsamples))
phist = histogram(rand(lnorm, 10000), legend=:false, grid=:false, tickfontsize=16, guidefontsize=16, left_margin=5mm, bottom_margin=10mm) 
plot!(size=(1000, 400))
ylabel!("Count")
xlabel!("Non-Point Source P Input")
```

## Lake Problem: Optimization Setup

1. Set parameters and number of samples for exogenous inflows (we'll use 1,000);
2. Define model function and bounds (we'll assume $0 \leq a_t \leq 0.1$);
3. Simulate objective and whether constraint is violated;
4. Return objective and constraint status.
5. Call optimizer (we'll use `DE()` with a maximum of 5,000 function evaluations).

## Lake Problem: Optimization Result

***What do you observe?***

```{julia}

# find critical value


crit(x) = (x^q/(1+x^q)) - b*x
Xcrit = find_zero(crit, (0.1, 1.5))

function lake(a, y, q, b, T)
    X = zeros(T+1, size(y, 2))
    # calculate states
    for t = 1:T
        X[t+1, :] = X[t, :] .+ a[t] .+ y[t, :] .+ (X[t, :].^q./(1 .+ X[t, :].^q)) .- b.*X[t, :]
    end
    return X
end

function lake_opt(a, y, q, b, T, Xcrit)
    X = lake(a, y, q, b, T)
    # calculate exceedance of critical value
    Pexceed = sum(X[101, :] .> Xcrit) / size(X, 2)
    failconst = [Pexceed - 0.1]
    return mean(a), failconst, [0.0]
end

# set bounds
bounds = [0.0ones(T) 0.1ones(T)]'
# optimize
obj(a) = lake_opt(a, y, q, b, T, Xcrit)
options = Options(f_calls_limit=5000)
results = Metaheuristics.optimize(obj, bounds, DE(options=options))

a = results.best_sol.x
pa = plot(a, tickfontsize=16, guidefontsize=16, ylabel="Point Source P Release", xlabel="Time", linewidth=3, legend=false, left_margin=5mm, bottom_margin=10mm)
```

## End-Of-Time P Concentrations

Now we can simulate to learn about how the solution performs.

```{julia}
#| cache: false

X = lake(a, y, q, b, T)

histogram(X[101, :], xlabel="End P Concentration", ylabel="Count",
    guidefontsize=16, tickfontsize=16, 
    legendfontsize=16, label=:false, bottom_margin=5mm, left_margin=5mm)
vline!([Xcrit], color=:red, linestyle=:dot, 
    label="Critical Value")
    plot!(size=(1000, 450))
```

## Lake P Concentration Trajectories

:::: {.columns}
::: {.column width=50%}

```{julia}
#| cache: false

pconc = plot(X, alpha=0.2,  linewidth=3,
    guidefontsize=16, tickfontsize=16, 
    legendfontsize=16, label=:false,
    legend=:topleft, bottom_margin=10mm, left_margin=5mm, grid=false)
hline!([Xcrit], color=:red, linestyle=:dot, 
    label="Critical Value")
plot!(size=(600, 600))
ylabel!("Lake P Concentration")
xlabel!("Time")
```

:::
::: {.column width=50%}
::: {.fragment .fade-in}

- Trajectories start jumping over the critical threshold later in the horizon.
- This **finite horizon** problem is **very common** for optimization problems with reliability constraints over fixed temporal windows.

:::
:::
::::

## Heuristic Algorithms Involve Lots of Choices!

Many choices were made in this optimization problem:

- Number of samples from the inflow distribution;
- Number of function evaluations;
- Strength of reliability constraint.

All of these affect the tradeoff between solution quality and computational expense.

# Key Takeaways

## General Takeaways

- Many challenges to using mathematical programming for general systems analysis.
- Can use simulation-optimization approaches.
- Tradeoff between lack of analytic solution and broader flexibility
- But be careful of computational expense and convergence!

## Challenges to Simulation-Optimization in General

- **Monte Carlo Error**: If constraints or objective is probabilistic, how many Monte Carlo runs are needed to ensure difference in function values is "real" and not stochastic noise.
- **Computational**: Can be expensive depending on the simulation model.
- **Local vs. Global Optima**: Depending on type of search algorithm, may not be able to guarantee more than a local optimum.
- **Transparency**: LP models are written down relatively clearly. Simulation models may have many important but hidden assumptions.

## Upcoming Schedule

**Friday**: Lab on simulation-optimization with the lake problem.

## Assessments

**Project Update**: Due Friday

**HW5**: Also due Friday.
