---
title: "BEE 4750 Homework 3: Uncertain Sea Level Rise and Levee Reliability"
format:
    html:        
        warning: true
        error: true
    ipynb:
        warning: true
        error: true
        code-annotation: below
jupyter: julia-1.9
format-links: []
---

::: {.content-visible when-format="ipynb"}
**Name**:

**ID**:
:::

::: {.callout-important icon=false}
### Due Date

Friday, 10/06/23, 9:00pm
:::

::: {.content-visible when-format="html"}

:::{.callout-caution}

If you are enrolled in the course, make sure that you use the GitHub Classroom link provided in Ed Discussion, or you may not be able to get help if you run into problems.

Otherwise, you can [find the Github repository here]({{< var github_org.repo >}}/hw03).

:::

:::

## Overview

### Instructions

This assignment asks you to conduct a Monte Carlo analysis of levee reliability in the face of uncertain changes to local sea levels. You will propagate uncertainty in equilibrium climate sensitivity through the energy balance model to obtain a distribution of temperatures, which will then drive a model of sea-level rise. You will finally use this distribution to assess the probability that a planned levee will achieve its desired reliability standard.

### Load Environment

The following code loads the environment and makes sure all needed packages are installed. This should be at the start of most Julia scripts.

```{julia}
#| output: false
import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
using Random
using Plots
using LaTeXStrings
using Distributions
using CSV
using DataFrames
```

## Problems (Total: 40 Points)

::: {.cell .markdown}
### Problem 1 (12 points)

Recall from class that the simple energy balance model (EBM) of planetary energy balance links changes in radiative forcing ($F$) to global mean temperature ($T$) changes through the discretized equation
$$T_{i+1} = T_{i} + \frac{F_i - \lambda T_i}{cd} \times \Delta t,$$
where $i$ is the current time step, $c = 4.184 \times 10^6$ J/K/m^2^ is the heat capacity of water per unit area, $d$ is the (uncertain) depth of the mixing layer, $\Delta t$ is the annual time step in seconds and $\lambda = F_{\text{2xCO}_2}/S$ is the climate feedback parameter in W/m^2^/$^\circ$ C, where $S$ is the equilibrium climate sensitivity (the uncertain equilibrium temperature change resulting from a doubling of atmospheric CO~2~). Finally, while total radiative forcing can be the result of non-aerosol and aerosol effects, we do not know the relative intensity of aerosol forcing, so we represent this with an uncertain aerosol scaling factor $\alpha$.

We can implement this model with the following Julia function. We will assume an ocean mixing depth $d = 100$ m and an aerosol scaling factor $\alpha = 1.3$ so we can focus on the uncertainty in $S$. 

The last technical concern is that "global mean temperature" does not make sense in absolute terms as a marker of climate change. Instead, we typically refer to temperature changes relative to some historical pre-industrial baseline. In this case, we will use the period from 1880-1900, though this choice can vary.
:::

```{julia}
# we need to split up the aerosol and non-aerosol forcings when we call the function
function energy_balance_model(S, forcing_aerosol, forcing_non_aerosol)
    d = 100 # ocean mixing depth [m]
    α = 1.3 # aerosol scaling factor
    F2xCO₂ = 4.0 # radiative forcing [W/m²] for a doubling of CO₂
    λ = F2xCO₂/S
    
    c = 4.184e6 # heat capacity/area [J/K/m²]
    C = c*d # heat capacity of mixed layer (per area)

    F = forcing_non_aerosol + α*forcing_aerosol # radiative forcing

    Δt = 31558152.0 # annual timestep [s]
    
    T = zero(F)
    for i in 1:length(F)-1
        T[i+1] = T[i] + (F[i] - λ*T[i])/C * Δt
    end
    # return temperature anomaly relative to 1880-1900 baseline
    return T .- mean(T[1:21]) 
end
```

Finally, we need to load some radiative forcing data. We will use the radiative forcing scenario RCP 8.5. We can load this data, which is in a `.csv` (comma-delimited) file, into a `DataFrame`, which is a tabular data structure. Rows and columns in a `DataFrame` can be accessed using their numerical index (like a matrix), but columns also have names; you can access a particular column in a dataframe `df` by name using `df.colname` or `df[:, "colname"]`.

Of note: this data set goes from 1750--2500, so you will need to take care to make sure you are using the right years at each step. For example, here we will constrain the data to 1880--2100, which is the period we are interested in.

```{julia}
# The CSV is read into a DataFrame object, and we specify that it is comma delimited
forcings_all_85 = CSV.read("data/ERF_ssp585_1750-2500.csv", DataFrame, delim=",")

# get the years corresponding to the forcings
t = Int64.(forcings_all_85[!,"year"]) # Ensure that years are interpreted as integers
# find the indices of the years 1880 and 2100
# we can do this with the indexin function
time_bounds = indexin([1880, 2100], t)
years = time_bounds[1]:time_bounds[2] # create range of years

# Separate out the individual components
forcing_co2_85 = forcings_all_85[years,"co2"]
# Get total aerosol and non-aerosol forcings
forcing_aerosol_rad_85 = forcings_all_85[years,"aerosol-radiation_interactions"]
forcing_aerosol_cloud_85 = forcings_all_85[years,"aerosol-cloud_interactions"]
forcing_aerosol_85 = forcing_aerosol_rad_85 + forcing_aerosol_cloud_85 # aerosol forcings
forcing_total_85 = forcings_all_85[years,"total"] 
forcing_non_aerosol_85 = forcing_total_85 - forcing_aerosol_85 # non-aerosol forcings

```

For this assignment, you can use the `forcing_aerosol_85` and `forcing_non_aerosol_85` vectors as is to correspond to the relevant forcings. You will need to use the vector `t` to find the appropriate years for analysis.

::: {.cell .markdown}

#### Problem 1.1 (3 points)

Assume that $S$ is distributed according to $\text{LogNormal}(\log(3.2), \log{2}/3)$ (as in class). Draw 10,000 samples from this distribution and make a histogram.

:::

***Solution***:

```{julia}
Random.seed!(1) # set random seed for reproducibility
S_dist = LogNormal(log(3.2), log(2)/3) # create the lognormal distribution
S_samples = rand(S_dist, 10000) # draw samples
# plot histogram without a legend but with appropriate axis labels
histogram(S_samples, xlabel="Equilibrium Climate Sensitivity (°C)", ylabel="Count", legend=:false)
```

::: {.cell .markdown}

#### Problem 1.2 (5 points)

Use the EBM to propagate your samples of $S$ to a distribution of global mean temperature. Plot the median and 90% predictive distribution (between the .05 and .95 quantiles) from 1880-2100.
:::

***Solution***:

First, we evaluate the EBM over the samples of $S$.

```{julia}
# get indices of years from 1850 
# initialize storage for EBM output
# this will be a matrix  of temperatures
# with rows corresponding to samples of S and columns corresponding to years
T = zeros(length(S_samples), length(years))
# loop over samples and evaluate the EBM
for (i, S) in pairs(S_samples)
    T[i, :] = energy_balance_model(S, forcing_aerosol_85, forcing_non_aerosol_85)
end
```

Next, let's calculate the quantiles and plot them.
```{julia}

# calculate quantiles. we will do this by setting up a matrix 
# where each row holds a different quantile
# we will keep the median separate, but this could be included in the matrix
T_quantiles = zeros(2, length(years))
T_quantiles[1, :] = quantile.(eachcol(T), 0.05)
T_quantiles[2, :] = quantile.(eachcol(T), 0.95)
T_median = quantile.(eachcol(T), 0.50)

# plot the median and quantiles
plot(t[years], T_median, 
    ribbon=(T_median .- T_quantiles[1, :], T_quantiles[2, :] .- T_median),
    color=:blue, fillalpha=0.2, xlabel="Year", 
    ylabel="Global Mean Temperature (°C)",
    label=:false)
```

::: {.cell .markdown}
#### Problem 1.3 (4 points)

Make a histogram of global mean temperature projections in 2100. If you compare this distribution to the distribution of $S$ from Problem 1.1, what do you observe?

:::

***Solution***:

```{julia}
# make the histogram
# the end keyword can be used to directly access the last index
histogram(T[:, end], xlabel="Global Mean Temperature (°C)", 
    ylabel="Count", legend=:false)
```

We can see that the broad shape of the distribution is similar, but it has a much wider variance: due to the high radiative forcings, a unit change in $S$ corresponds to a higher temperature change by 2100.

::: {.cell .markdown}
### Problem 2 (15 points)

Changes to global temperatures cause changes in global sea levels through several mechanisms, including thermal expansion (the change in ocean volume due to increased heat content) and melting land-based ice. One simple way to represent this link is through the following model, proposed by [Rahmstorf (2007)](https://doi.org/10.1126/science.1135456). 

$$\frac{dH}{dt} = a(T-T_0),$$
where $H$ is the global mean sea level in mm, $T$ is global mean temperature, $T_0$ is an equilibrium temperature (where there is no change in sea levels), and $a$ is a proportionality constant. This model can be discretized to give
$$H_{i+1} - H_i = a (T_i - T_0).$$

Note that, like with global mean temperature, the notion of "global mean sea level" does not make sense in absolute terms (were sea levels ever at "zero"?).  Instead, we want to normalize this relative to some historical baseline. In this case (with a view towards Problem 3), we will compute our sea levels relative to the 2010 sea level. Note that in addition to the model parameters, we also need an initial sea-level parameter $H_0$ which will give us the right anomaly level.

The best estimates for these parameters are:

- $a = 1.86$;
- $H_0 = -223$;
- $T_0 = -0.62$
:::

::: {.cell .markdown}
#### Problem 2.1 (5 points)

Write a function `sea_level_model()` to implement the mathematical sea-level rise model described above. It should take in needed parameters and a vector of temperatures and return a vector of sea levels. To test your function, use the provided temperature series `historical_temps` (read in below) to compute the global mean sea level anomaly in 2022 (the last year of the dataset) with the parameter values above; you should get a value of approximately 43mm.

```{julia}
historical_temp_data = CSV.read("data/HadCRUT.5.0.1.0.analysis.summary_series.global.annual.csv", DataFrame, delim=",")
# column 2 is the temperature anomaly, column 1 is the year
temp_bds = indexin([1880, 1900], historical_temp_data[!, 1]) # find the index of 2010 for normalization
historical_temp_data[:, 2] .-= mean(historical_temp_data[temp_bds[1]:temp_bds[2], 2])
historical_temps = historical_temp_data[temp_bds[1]:end, 2]
```
:::

***Solution***:

The function should take in parameters `a` (temperature sensitivity), `H₀` (an initial sea-level), and `T₀` (equilibrium temperature). The actual function can be written in a few different ways; here we will use a loop, but you could also use `cumsum()` to calculate the running sum of temperature effects (`a (T[t] .- T₀)`) over the equilibrium temperature.

```{julia}
# T is the vector of temperatures
function sea_level_model(T, a, H₀, T₀)
    H = zeros(length(T) + 1)
    H[1] = H₀
    for i = 2:length(T)+1
        H[i] = a * (T[i-1] - T₀) + H[i-1]
    end
    # need to normalize relative to the right baseline; this is the number of years
    # from 1880 to 2010
    return H[2:end] .- H[131]
end
```

Now, let's check that we get the right answer for the historical temperature set.

```{julia}
historical_sea_levels = sea_level_model(historical_temps, 1.86, 223.0, -0.62)
# the next line returns an error if the statement does not match
# Base.round(...; digits=...) lets us round a value
@assert Base.round(historical_sea_levels[end]; digits=0) == 43
```

::: {.cell .markdown}
#### Problem 2.2 (5 points)

Evaluate `sea_level_model()` using the projected temperature ensemble from Problem 1. Plot the 90% projection interval of the sea levels.
:::

***Solution***:

First, we propagate the temperature ensemble through the sea-level rise model:
```{julia}
H = zeros(size(T))
for i = 1:size(T)[1]
    H[i, :] = sea_level_model(T[i, :], 1.77, 0.15, -0.63)
end
```

Now, let's plot the 90% projection interval (as in Problem 1.2):

```{julia}
H_quantiles = zeros(2, length(years))
H_quantiles[1, :] = quantile.(eachcol(H), 0.05)
H_quantiles[2, :] = quantile.(eachcol(H), 0.95)
H_median = quantile.(eachcol(H), 0.50)

# plot the median and quantiles
plot(t[years], H_median, 
    ribbon=(H_median .- H_quantiles[1, :], H_quantiles[2, :] .- H_median),
    color=:blue, fillalpha=0.2, xlabel="Year", 
    ylabel="Global Mean Sea Level Anomaly (mm)",
    label=:false)
```

::: {.cell .markdown}
#### Problem 2.3 (5 points)

Make a histogram of the sea-level anomaly in 2100. What can you observe about how the ECS uncertainty has impacted sea-level uncertainty under this radiative forcing scenario? What might the implications be of only using the best-estimate ECS value?

:::

***Solution***: 

```{julia}
histogram(H[:, end], legend=:false, xlabel="Sea Level Anomaly in 2100 (mm)", 
    ylabel="Count")
```

We can observe that the long upper tail is persistent from the original ECS and temperature distributions. This might suggest that ignoring this uncertainty could result in an under-estimation of the worst-case risks associated with sea-level rise. Further, as there is a larger amount of probability mass above this level than below it due to the distribution's skew, it is more likely that we under-estimate the resulting risks than over-estimate.


::: {.cell .markdown}
### Problem 3 (13 points)

You've been asked to consult on a levee reliability analysis. For context, levees in the United States are supposed to only fail once in 100 years, or, in other words, to have at most a 1% chance of failure in a given year. We will assume for this problem that the only way in which a levee fails is by being overtopped (note: this is unrealistic).

We can assess the probability of levee overtopping by comparing its height to a distribution of extreme sea levels. A common approach is to look at the distribution of the highest sea level each year. These extreme sea levels can be obtained by combining the absolute sea level (we will use our distribution of global sea levels for this), the rate of subsidence (how much the ground sinks), and the distribution of storm tides (the highest tide level, which is often the result of storm surges combining with high tide). 

Assume for this problem that: 

1. the annual rate of subsidence $\nu$ is 1.2mm/yr;
2. the distribution of annual storm tide maxima, above the mean sea level, is (and is expected to continue to be) given by a $\text{GeneralizedExtremeValue}(900, 25, 0.3)$ distribution, which looks like this:
```{julia}
tide_distribution = GeneralizedExtremeValue(900, 25, 0.3)
    histogram(rand(tide_distribution, 10000), xlabel="Storm Tide Height (mm)", ylabel="Count", legend=:false)
```

Feel free to just sample from `tide_distribution` in your solution below.
:::

::: {.cell .markdown}
#### Problem 3.1 (2 points)

How would you use your sea-level simulations and the above information to compute a distribution of extreme sea levels in 2100 relative to 2010 mean sea level? Write down the approach in clear steps, with equations as needed.
:::

***Solution***:

1. We start with our distribution of global sea levels in 2100 (relative to the 2010 mean sea level from Problem 2). 
2. For each of these (call a given realization $H_n$), we need to add the amount of subsidence from 2010 through 2100, which is $\nu \times (2100 - 2010 + 1)$. 
3. We then draw 10,000 samples $x_n$ of a storm tide maximum from the given distribution.

Then a single simulation of a storm tide is $H_n + \nu_n \times (2100 - 2010 + 1) + x_n$, and we have obtained a distribution of 10,000 of these through this procedure.

::: {.cell .markdown}
#### Problem 3.2 (3 points)

Follow the steps above and produce a histogram of the extreme sea levels in 2100 relative to 2010.
:::

***Solution***:

```{julia}
ν = 1.2 * (2100 - 2010 + 1) # total subsdience from 2010 through 2100
storm_tide_max = rand(tide_distribution, 10000) # storm tide extremes
sea_level_max = H[:, end] + storm_tide_max .+ ν
histogram(sea_level_max, legend=:false, xlabel="Extreme Sea Levels in 2100 (mm)", ylabel="Count")
```

::: {.cell .markdown}
#### Problem 3.3 (5 points)

The current levee was heightened in 2010 to 2m above the 2010 mean sea level. Based on your analysis above, what is the probability that the levee will be overtopped in 2100 (remember that the reliability standard is 1%)?
:::

***Solution***:

We need to see how often our samples exceed 2m. We can do this by broadcasting or with a loop. Remember to account for the conversion from m to mm!

```{julia}
# broadcast over samples and find values exceeding 2m
exceedances = sea_level_max .> 2000
prob_exceedance = sum(exceedances) / length(sea_level_max)
```

So we can estimate that the levee could be overtopped with a 5% probability in 2100, which is well below the reliability standard.

::: {.cell .markdown}
#### Problem 3.4 (3 points)

Based on your analysis, would you recommend that the levee be heightened again in the future, and if so, how high? What other information might you need, if any, to make your recommendation?
:::

***Solution***: It seems that the levee should be re-heightened, but the level will depend on a number of factors, so there are many acceptable answers, depending on cost (do you just build to reach the 1% standard or build higher?) and possible damages in the event of a flood (based on the anticipated exposure and vulnerability in the future).

::: {.cell .markdown}
## References

List any external references consulted, including classmates.
:::